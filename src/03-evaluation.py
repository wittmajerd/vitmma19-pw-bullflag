# Model evaluation script
# This script evaluates the trained model on the test set and generates metrics.
from utils import setup_logger

logger = setup_logger()

def evaluate():
    logger.info("Evaluating model...")

if __name__ == "__main__":
    evaluate()
